library("scales")
library("tidyr")
library("dplyr")
library("reshape")
library("zoo") # na.approx()
# setwd("D:/Documents/these_pablo/Alteckendorf2016/R")
# MAC
# setwd("/Users/DayTightChunks/Documents/PhD/Routput/Alteck/R")
# Mac-WIN
# setwd("C:/Users/DayTightChunks/Documents/Models/pesti-beach16/Analysis/Data")
getwd()
q = read.csv2(file.path(path, "Data/groupAlteck2016_R.csv"))
q$Vol.L = q$Vol2min * 1000
q = q[ , c("Date", "DateCheck", "Q.HW1", "DayMoYr", "Vol.L", "sampleQ", "Type", "SubWeeks", "Weeks", "WeekNo" )]
names(q)
mark = read.csv(file.path(path, "Data/MarkerResponse_R05.csv"))
mark$ti = as.POSIXct(strptime(mark$ti, "%Y-%m-%d %H:%M", tz="EST"))
mark$tf = as.POSIXct(strptime(mark$tf, "%Y-%m-%d %H:%M", tz="EST"))
mark$Sampled = as.character(mark$Sampled)
mark$ISO.x = ifelse(is.na(mark$diss.d13C), F, T)
mark = mark[, c("WeekSubWeek", "ti", "tf",
"Duration.Hrs", "Volume.m3", "Sampled.Hrs", "Sampled", "ISO.x",
# "AveDischarge.m3.h",
"Conc.mug.L" , "Conc.SD",
# "Vol.SPE.L", "Conc.in500uL",
"OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD",
"N.x", "diss.d13C", "SD.d13C",
"MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD" #,
#"N.y",  "filt.d13C",  "filt.SD.d13C" #,
#"DD13C.diss", "DD13C.filt"
)]
names(mark)
# Delete repeated W6 observation, or with NA in week markers
# mark = mark[mark$WeekSubWeek != as.character("W6-3j7") & !is.na(mark$WeekSubWeek), ]
q$Date = as.POSIXct(strptime(q$DateCheck, "%d/%m/%Y %H:%M", tz="EST"))
q$DayMoYr = as.POSIXct(strptime(q$DateCheck, "%d/%m/%Y", tz="EST"))
q$Min = 2.0
CHECKO = F
if (CHECKO){
sum(is.na(q$Date))
naDates = q[is.na(q$Date == TRUE),]
duplicateAlteck <- q[duplicated(q$DateCheck),]
head(duplicateAlteck)
}
qDay <- q %>%
group_by(DayMoYr) %>%
dplyr::summarize(Volday.L = sum(Vol.L))
qDay$VolTot.m3 = round(qDay$Volday.L/10^3, 3)
qTime = merge(time, qDay, by = "DayMoYr", all = T)
qTime_cal = subset(qTime, !is.na(VolTot.m3))
qTime_cal = qTime_cal[, c("Jdays", "VolTot.m3")]
names(qTime_cal) = c("Jdays", "Qm3")
mean(qTime$VolTot.m3, na.rm = T)
sd(qTime$VolTot.m3, na.rm = T)
Volm3_tss = qTime[,c("Jdays", "VolTot.m3")]
Volm3_tss$VolTot.m3 = ifelse(is.na(Volm3_tss$VolTot.m3), -1.0, Volm3_tss$VolTot.m3)
if (F) {
write.table(Volm3_tss, "BEACH_R/q_obs_m3day.tss", sep="\t", row.names = F, col.names = F)
write.table(qTime_cal, "BEACH_R/q_out_cal.tss", sep="\t", row.names = F, col.names = T) # m3day
}
if (F) {
## Convert m3.h -> m3
qDay <- q %>%
group_by(DayMoYr) %>%
dplyr::summarize(Q.m3 = sum(Vol2min))
qDay$Q.mm = (qDay$Q.m3/catchment_area)*10^3
qDay$time = seq.int(nrow(qDay))
# Qm3/day
DischQm3_tss = qDay[,c("time", "Q.m3")]
write.table(DischQm3_tss, "BEACH_R/disch_m3day.tss", sep="\t", row.names = F, col.names = F)
# Qmm/day
DischQmm_tss = qDay[,c("time", "Q.mm")]
write.table(DischQmm_tss, "BEACH_R/disch_mmday.tss", sep="\t", row.names = F)
}
names(mark)
# First Merge
qm = merge(q, mark, by.x = "Date", by.y = "ti", all = T)
# Get only the markers for "tf" (end of sample period)
tf = mark[, c("tf", "Sampled", "Conc.mug.L", "Conc.SD", "diss.d13C", "SD.d13C",
"OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD",
"MES.mg.L" , "MES.sd" , "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD")]
tf$ISO.y = ifelse(is.na(tf$diss.d13C), F, T)
# Second merge
qm = merge(qm, tf, by.x = "Date", by.y = "tf", all = T)
# Sampled vs. non-sampled
qm$Sampled.x = ifelse(is.na(qm$Sampled.x), qm$Sampled.y, qm$Sampled.x)
qm$Sampled.x = na.locf(qm$Sampled.x)
# Input end of sample measure
qm$Conc.mug.L = ifelse(is.na(qm$Conc.mug.L.x), qm$Conc.mug.L.y, qm$Conc.mug.L.x)
qm$Conc.mug.L = na.locf(qm$Conc.mug.L, na.rm = F) # Copy/Drag cells down
qm$Conc.mug.L = ifelse(qm$Sampled.x=="Sampled", qm$Conc.mug.L, NA) # Correct carry-over to non-sampled.
qm$Conc.SD = ifelse(is.na(qm$Conc.SD.x), qm$Conc.SD.y, qm$Conc.SD.x)
qm$Conc.SD = na.locf(qm$Conc.SD, na.rm = F) # Copy/Drag cells down
qm$Conc.SD = ifelse(qm$Sampled.x=="Sampled", qm$Conc.SD, NA) # Correct carry-over to non-sampled.
# ISO vs. non-ISO (Special case)
qm$ISO.x = ifelse(is.na(qm$ISO.x), qm$ISO.y, qm$ISO.x)
qm$ISO.x = na.locf(qm$ISO.x)
qm$diss.d13C = ifelse(is.na(qm$diss.d13C.x), qm$diss.d13C.y, qm$diss.d13C.x)
qm$diss.d13C = na.locf(qm$diss.d13C, na.rm = F) # Copy/Drag cells down
qm$diss.d13C = ifelse(qm$ISO.x==T, qm$diss.d13C, NA) # Correct carry-over to non-sampled.
qm$SD.d13C = ifelse(is.na(qm$SD.d13C.x), qm$SD.d13C.y, qm$SD.d13C.x)
qm$SD.d13C = na.locf(qm$SD.d13C, na.rm = F) # Copy/Drag cells down
qm$SD.d13C = ifelse(qm$ISO.x==T, qm$SD.d13C, NA) # Correct carry-over to non-sampled.
# Repeat for
# OXA
qm$OXA_mean = ifelse(is.na(qm$OXA_mean.x), qm$OXA_mean.y, qm$OXA_mean.x)
qm$OXA_mean = na.locf(qm$OXA_mean, na.rm = F) # Copy/Drag cells down
qm$OXA_mean = ifelse(qm$Sampled.x=="Sampled", qm$OXA_mean, NA) # Correct carry-over to non-sampled.
qm$OXA_SD = ifelse(is.na(qm$OXA_SD.x), qm$OXA_SD.y, qm$OXA_SD.x)
qm$OXA_SD = na.locf(qm$OXA_SD, na.rm = F) # Copy/Drag cells down
qm$OXA_SD = ifelse(qm$Sampled.x=="Sampled", qm$OXA_SD, NA) # Correct carry-over to non-sampled.
# ESA
qm$ESA_mean = ifelse(is.na(qm$ESA_mean.x), qm$ESA_mean.y, qm$ESA_mean.x)
qm$ESA_mean = na.locf(qm$ESA_mean, na.rm = F) # Copy/Drag cells down
qm$ESA_mean = ifelse(qm$Sampled.x=="Sampled", qm$ESA_mean, NA) # Correct carry-over to non-sampled.
qm$ESA_SD = ifelse(is.na(qm$ESA_SD.x), qm$ESA_SD.y, qm$ESA_SD.x)
qm$ESA_SD = na.locf(qm$ESA_SD, na.rm = F) # Copy/Drag cells down
qm$ESA_SD = ifelse(qm$Sampled.x=="Sampled", qm$ESA_SD, NA) # Correct carry-over to non-sampled.
# Suspended solids
qm$MES.mg.L = ifelse(is.na(qm$MES.mg.L.x), qm$MES.mg.L.y, qm$MES.mg.L.x)
qm$MES.mg.L = na.locf(qm$MES.mg.L, na.rm = F) # Copy/Drag cells down
qm$MES.mg.L = ifelse(qm$Sampled.x=="Sampled", qm$MES.mg.L, NA) # Correct carry-over to non-sampled.
qm$MES.sd = ifelse(is.na(qm$MES.sd.x), qm$MES.sd.y, qm$MES.sd.x)
qm$MES.sd = na.locf(qm$MES.sd, na.rm = F) # Copy/Drag cells down
qm$MES.sd = ifelse(qm$Sampled.x=="Sampled", qm$MES.sd, NA) # Correct carry-over to non-sampled.
# SM concentration in Suspendeed soilds
qm$Conc.Solids.mug.gMES = ifelse(is.na(qm$Conc.Solids.mug.gMES.x), qm$Conc.Solids.mug.gMES.y, qm$Conc.Solids.mug.gMES.x)
qm$Conc.Solids.mug.gMES = na.locf(qm$Conc.Solids.mug.gMES, na.rm = F) # Copy/Drag cells down
qm$Conc.Solids.mug.gMES = ifelse(qm$Sampled.x=="Sampled", qm$Conc.Solids.mug.gMES, NA) # Correct carry-over to non-sampled.
qm$Conc.Solids.ug.gMES.SD = ifelse(is.na(qm$Conc.Solids.ug.gMES.SD.x), qm$Conc.Solids.ug.gMES.SD.y, qm$Conc.Solids.ug.gMES.SD.x)
qm$Conc.Solids.ug.gMES.SD = na.locf(qm$Conc.Solids.ug.gMES.SD, na.rm = F) # Copy/Drag cells down
qm$Conc.Solids.ug.gMES.SD = ifelse(qm$Sampled.x=="Sampled", qm$Conc.Solids.ug.gMES.SD, NA) # Correct carry-over to non-sampled.
names(qm)
qm = qm[, c("Date", "tf", "DateCheck", "Q.HW1", "DayMoYr" ,"Vol.L", "sampleQ","Type", "Sampled.x","ISO.x",
"SubWeeks", "Weeks", "WeekNo", "Min" ,"WeekSubWeek" ,"Duration.Hrs",  "Volume.m3" , "Sampled.Hrs",
"Conc.mug.L", "Conc.SD", "MES.mg.L", "MES.sd", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD", "diss.d13C", "SD.d13C",
"OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD" )]
# qm = merge(q, mark, by.x = "SubWeeks", by.y = "WeekSubWeek", all = T)
# Dissolved
qm$SmetOut_ug.obs = qm$Vol.L*qm$Conc.mug.L
qm$SmetOut_ug.sd = qm$Vol.L*qm$Conc.SD
qm$OxaOut_ug.obs =  qm$Vol.L*qm$OXA_mean
qm$OxaOut_ug.sd =  qm$Vol.L*qm$OXA_SD
qm$EsaOut_ug.obs =  qm$Vol.L*qm$ESA_mean
qm$EsaOut_ug.sd =  qm$Vol.L*qm$ESA_SD
# Suspended Solids (SS)
# Smet.ug in SS = ug/g * (MES [mg/L] * [1g/10^3mg])  * Vol [L]
qm$SmetSS_ug.obs = qm$Conc.Solids.mug.gMES * (qm$MES.mg.L*1/10^3)  * qm$Vol.L
qm$SmetSS_ug.sd = qm$Conc.Solids.ug.gMES.SD * (qm$MES.sd*1/10^3)  * qm$Vol.L
qm$MassDelta.obs = qm$SmetOut_ug.obs*qm$diss.d13C
qm$MassDelta.sd = qm$SmetOut_ug.sd*qm$SD.d13C
names(qm)
qmDay <- qm %>%
group_by(DayMoYr, SubWeeks) %>%
dplyr::summarize(Volday.L = sum(Vol.L),
SmpHrs = sum(Min)/60,
SmOut_ug.obs = sum(SmetOut_ug.obs),
SmOut_ug.sd = (sum(SmetOut_ug.sd^2))^0.5, # Cumulative SD
OxOut_ug.obs = sum(OxaOut_ug.obs),
OxOut_ug.sd = (sum(OxaOut_ug.sd^2))^0.5, # Cumulative SD
EsOut_ug.obs = sum(EsaOut_ug.obs),
EsOut_ug.sd = (sum(EsaOut_ug.sd^2))^0.5, # Cumulative SD
ConcSmOut_ugL.obs = SmOut_ug.obs/Volday.L, # Smet
ConcSmOut_ugL.sd = SmOut_ug.sd/Volday.L,
ConcOxOut_ugL.obs = OxOut_ug.obs/Volday.L, # Oxa
ConcOxOut_ugL.sd = OxOut_ug.sd/Volday.L,
ConcEsOut_ugL.obs = EsOut_ug.obs/Volday.L, # Esa
ConcEsOut_ugL.sd = EsOut_ug.sd/Volday.L,
delta.obs = sum(MassDelta.obs)/(sum(SmetOut_ug.obs)),
delta.sd = (sum(MassDelta.sd^2))^0.5/(sum(SmetOut_ug.sd^2))^0.5
)
write.csv(qmDay,
'BEACH_R/allOut_multiDay_R00.csv', row.names = F)
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv", row.names = F)
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv")
View(qmDay)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018_csv"))
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"))
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ",")
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";")
View(clust)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";", dec = ".")
View(clust)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";", dec = ",")
View(clust)
View(qm)
View(mark)
path = file.path("/Users/DayTightChunks/Documents/PhD/hydrological-monitoring")
time = read.csv2("/Users/DayTightChunks/Documents/PhD/Models/phd-model-master/Analysis/Data/Time.csv")
time$DayMoYr = as.POSIXct(strptime(time$Date, "%d/%m/%Y", tz="EST"))
source(file.path(path, "global.R"))
out = read.csv(file.path(path, "Data/MarkerResponse_R05.csv"))
View(out)
qmDay(names)
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv")
qmDay(names)
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv")
(qmDay)
names(qmDay)
qmDay = qmDay[, !c("DayMoYr")]
qmDay = qmDay[, c("DayMoYr", "SubWeeks", "Volday.L", "SmpHrs",
"ConcSmOut_ugL.obs", "ConcSmOut_ugL.sd" ,
"SmOut_ug.obs", "SmOut_ug.sd",
"delta.obs", "delta.sd" )]
names(qmDay)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";", dec = ",")
names(clust)
clust = clust[, c("Events", "WeekSubWeek", "Q.Ave", "T.Hrs", "Vol", "Q.Max", "Cluster",  "EventLabel")]
out2 = out[, c("WeekSubWeek", "ti", "tf",  "Duration.Hrs", "Volume.m3", "Sampled.Hrs")]
View(out2)
out2 = out[, c("WeekSubWeek", "ti", "tf")]
outlet = merge(out2, clust, by = "WeekSubWeek", all = T)
View(outlet)
outlet = merge(outlet , qmDay, by.x = "WeekSubWeek", by.y = "SubWeeks", all = T)
View(time)
names(time)
time = time[, c( "Jdays", "DayMoYr")]
outlet$DayMoYr = as.POSIXct(strptime(outlet$DayMoYr, "%Y-%m-%d", tz="EST"))
outlet = merge(time, outlet, by = "DayMoYr", all = F)
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv")
qmDay = qmDay[, c("DayMoYr", "SubWeeks", "Volday.L", "SmpHrs",
"ConcSmOut_ugL.obs", "ConcSmOut_ugL.sd" ,
"SmOut_ug.obs", "SmOut_ug.sd",
"delta.obs", "delta.sd" )]
names(qmDay)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";", dec = ",")
clust = clust[, c("Events", "WeekSubWeek", "Q.Ave", "T.Hrs", "Vol", "Q.Max", "Cluster",  "EventLabel")]
names(clust)
# Adding markers: ti and tf
out2 = out[, c("WeekSubWeek", "ti", "tf")]
outlet = merge(out2, clust, by = "WeekSubWeek", all = T)
outlet = merge(outlet , qmDay, by.x = "WeekSubWeek", by.y = "SubWeeks", all = T)
outlet$DayMoYr = as.POSIXct(strptime(outlet$DayMoYr, "%Y-%m-%d", tz="EST"))
time = time[, c( "Jdays", "DayMoYr")]
outlet2 = merge(time, outlet, by = "DayMoYr", all = F)
View(outlet2)
outlet = merge(time, outlet, by = "DayMoYr", all = F)
View(outlet)
write.csv(outlet,
'BEACH_R/visuals_b2l_R04.csv', row.names = F)
View(q)
q = read.csv2(file.path(path, "Data/groupAlteck2016_R.csv"))
View(q)
q = q[ , c("Date", "Q.HW1", "DayMoYr", "Vol.L", "SubWeeks" )]
q = read.csv2(file.path(path, "Data/groupAlteck2016_R.csv"))
q$Vol.L = q$Vol2min * 1000
q = q[ , c("Date", "Q.HW1", "DayMoYr", "Vol.L", "SubWeeks" )]
q$Q.Ls = q$Q.HW1*1000/60
View(time)
time$tDayMoYr = as.POSIXct(strptime(time$Date, "%d/%m/%Y  %H:%M", tz="EST"))
time = read.csv2("/Users/DayTightChunks/Documents/PhD/Models/phd-model-master/Analysis/Data/Time.csv")
time$DayMoYr = as.POSIXct(strptime(time$Date, "%d/%m/%Y", tz="EST"))
time$tDayMoYr = as.POSIXct(strptime(time$Date, "%d/%m/%Y  %H:%M", tz="EST"))
time$tDayMoYr = as.POSIXct(strptime(time$Date, "%d/%m/%Y %H:%M", tz="EST"))
q = read.csv2(file.path(path, "Data/groupAlteck2016_R.csv"))
q$Vol.L = q$Vol2min * 1000
q = q[ , c("Date", "DateCheck", "Q.HW1", "DayMoYr", "Vol.L", "sampleQ", "Type", "SubWeeks", "Weeks", "WeekNo" )]
names(q)
mark = read.csv(file.path(path, "Data/MarkerResponse_R05.csv"))
mark$ti = as.POSIXct(strptime(mark$ti, "%Y-%m-%d %H:%M", tz="EST"))
mark$tf = as.POSIXct(strptime(mark$tf, "%Y-%m-%d", tz="EST"))
mark$Sampled = as.character(mark$Sampled)
mark$ISO.x = ifelse(is.na(mark$diss.d13C), F, T)
mark = mark[, c("WeekSubWeek", "ti", "tf",
"Duration.Hrs", "Volume.m3", "Sampled.Hrs", "Sampled", "ISO.x",
# "AveDischarge.m3.h",
"Conc.mug.L" , "Conc.SD",
# "Vol.SPE.L", "Conc.in500uL",
"OXA_mean", "OXA_SD", "ESA_mean", "ESA_SD",
"N.x", "diss.d13C", "SD.d13C",
"MES.mg.L", "MES.sd", "MO.mg.L", "Conc.Solids.mug.gMES", "Conc.Solids.ug.gMES.SD" #,
#"N.y",  "filt.d13C",  "filt.SD.d13C" #,
#"DD13C.diss", "DD13C.filt"
)]
names(mark)
time$tDayMoYr = as.POSIXct(strptime(time$Date, "%d/%m/%Y %H:%M", tz="EST"))
time$tDayMoYr = format(round(time$tDayMoYr, units = "day"), "%Y-%m-%d %H:%M")
time$tDayMoYr = format(time$tDayMoYr, "%Y-%m-%d %H:%M")
time$tDayMoYr = format(as.POSIXct(time$tDayMoYr), "%Y-%m-%d %H:%M")
time$tDayMoYr = format(as.POSIXct(time$DayMoYr), "%Y-%m-%d %H:%M")
time$tDayMoYr = format(as.POSIXct(time$DayMoYr), "%Y-%m-%d %H:%M:%S")
time = read.csv2("/Users/DayTightChunks/Documents/PhD/Models/phd-model-master/Analysis/Data/Time.csv")
time$DayMoYr = as.POSIXct(strptime(time$Date, "%d/%m/%Y", tz="EST"))
time$tDayMoYr = format(as.POSIXct(time$DayMoYr), "%Y-%m-%d %H:%M:%S")
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv")
qmDay = qmDay[, c("DayMoYr", "SubWeeks", "Volday.L", "SmpHrs",
"ConcSmOut_ugL.obs", "ConcSmOut_ugL.sd" ,
"SmOut_ug.obs", "SmOut_ug.sd",
"delta.obs", "delta.sd" )]
names(qmDay)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";", dec = ",")
clust = clust[, c("Events", "WeekSubWeek", "Q.Ave", "T.Hrs", "Vol", "Q.Max", "Cluster",  "EventLabel")]
names(clust)
# Adding markers: ti and tf
out2 = out[, c("WeekSubWeek", "ti", "tf")]
outlet = merge(out2, clust, by = "WeekSubWeek", all = T)
outlet = merge(outlet , qmDay, by.x = "WeekSubWeek", by.y = "SubWeeks", all = T)
outlet$DayMoYr = as.POSIXct(strptime(outlet$DayMoYr, "%Y-%m-%d", tz="EST"))
time = time[, c( "Jdays", "DayMoYr", "tDayMoYr")]
outlet = merge(time, outlet, by = "DayMoYr", all = F)
write.csv(outlet,
'BEACH_R/visuals_b2l_R04.csv', row.names = F)
# For plotting Discharge gainst chemo-bars
q = read.csv2(file.path(path, "Data/groupAlteck2016_R.csv"))
q$Vol.L = q$Vol2min * 1000
q = q[ , c("Date", "Q.HW1", "DayMoYr", "Vol.L", "SubWeeks" )]
q$Q.Ls = q$Q.HW1*1000/60
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv")
qmDay = qmDay[, c("DayMoYr", "SubWeeks", "Volday.L", "SmpHrs",
"ConcSmOut_ugL.obs", "ConcSmOut_ugL.sd" ,
"SmOut_ug.obs", "SmOut_ug.sd",
"delta.obs", "delta.sd" )]
names(qmDay)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";", dec = ",")
clust = clust[, c("Events", "WeekSubWeek", "Q.Ave", "T.Hrs", "Vol", "Q.Max", "Cluster",  "EventLabel")]
names(clust)
# Adding markers: ti and tf
out2 = out[, c("WeekSubWeek", "ti", "tf")]
outlet = merge(out2, clust, by = "WeekSubWeek", all = T)
outlet = merge(outlet , qmDay, by.x = "WeekSubWeek", by.y = "SubWeeks", all = T)
outlet$DayMoYr = as.POSIXct(strptime(outlet$DayMoYr, "%Y-%m-%d", tz="EST"))
time = time[, c( "Jdays","tDayMoYr", "DayMoYr")]
outlet = merge(time, outlet, by = "DayMoYr", all = F)
View(outlet)
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv")
qmDay = qmDay[, c("DayMoYr", "SubWeeks", "Volday.L", "SmpHrs",
"ConcSmOut_ugL.obs", "ConcSmOut_ugL.sd" ,
"SmOut_ug.obs", "SmOut_ug.sd",
"delta.obs", "delta.sd" )]
names(qmDay)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";", dec = ",")
clust = clust[, c("Events", "WeekSubWeek", "Q.Ave", "T.Hrs", "Vol", "Q.Max", "Cluster",  "EventLabel")]
names(clust)
# Adding markers: ti and tf
out2 = out[, c("WeekSubWeek", "ti", "tf")]
outlet = merge(out2, clust, by = "WeekSubWeek", all = T)
outlet = merge(outlet , qmDay, by.x = "WeekSubWeek", by.y = "SubWeeks", all = T)
outlet$DayMoYr = as.POSIXct(strptime(outlet$DayMoYr, "%Y-%m-%d", tz="EST"))
time = time[, c("tDayMoYr", "Jdays", "DayMoYr")]
outlet = merge(time, outlet, by = "DayMoYr", all = F)
outlet$ts = max(outlet$tDayMoYr, outlet$ti)
outlet$ts = ifelse(outlet$tDayMoYr > outlet$ti, outlet$tDayMoYr, outlet$ti)
View(outlet)
outlet$ts = max(as.POSIXct(outlet$tDayMoYr), as.POSIXct(outlet$ti))
View(outlet)
outlet$ts = max(as.POSIXct(outlet$tDayMoYr,  tz="EST"), as.POSIXct(outlet$ti,  tz="EST"))
time$tDayMoYr = as.POSIXct(time$tDayMoYr,  tz="EST")
outlet$tDayMoYr = as.POSIXct(outlet$tDayMoYr,  tz="EST")
outlet$ts = max(as.POSIXct(outlet$tDayMoYr,  tz="EST"), as.POSIXct(outlet$ti,  tz="EST"))
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv")
qmDay = qmDay[, c("DayMoYr", "SubWeeks", "Volday.L", "SmpHrs",
"ConcSmOut_ugL.obs", "ConcSmOut_ugL.sd" ,
"SmOut_ug.obs", "SmOut_ug.sd",
"delta.obs", "delta.sd" )]
names(qmDay)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";", dec = ",")
clust = clust[, c("Events", "WeekSubWeek", "Q.Ave", "T.Hrs", "Vol", "Q.Max", "Cluster",  "EventLabel")]
names(clust)
# Adding markers: ti and tf
out2 = out[, c("WeekSubWeek", "ti", "tf")]
outlet = merge(out2, clust, by = "WeekSubWeek", all = T)
outlet = merge(outlet , qmDay, by.x = "WeekSubWeek", by.y = "SubWeeks", all = T)
outlet$DayMoYr = as.POSIXct(strptime(outlet$DayMoYr, "%Y-%m-%d", tz="EST"))
time = time[, c("tDayMoYr", "Jdays", "DayMoYr")]
outlet = merge(time, outlet, by = "DayMoYr", all = F)
Sys.setlocale("LC_ALL", "English")
# Plotting functions
library("scales")
library("tidyr")
library("dplyr")
library("reshape")
library("zoo") # na.approx()
path = file.path("/Users/DayTightChunks/Documents/PhD/hydrological-monitoring")
time = read.csv2("/Users/DayTightChunks/Documents/PhD/Models/phd-model-master/Analysis/Data/Time.csv")
time$DayMoYr = as.POSIXct(strptime(time$Date, "%d/%m/%Y", tz="EST"))
time$tDayMoYr = format(as.POSIXct(time$DayMoYr), "%Y-%m-%d %H:%M:%S")
source(file.path(path, "global.R"))
out = read.csv(file.path(path, "Data/MarkerResponse_R05.csv"))
names(out)
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv")
qmDay = qmDay[, c("DayMoYr", "SubWeeks", "Volday.L", "SmpHrs",
"ConcSmOut_ugL.obs", "ConcSmOut_ugL.sd" ,
"SmOut_ug.obs", "SmOut_ug.sd",
"delta.obs", "delta.sd" )]
names(qmDay)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";", dec = ",")
clust = clust[, c("Events", "WeekSubWeek", "Q.Ave", "T.Hrs", "Vol", "Q.Max", "Cluster",  "EventLabel")]
names(clust)
# Adding markers: ti and tf
out2 = out[, c("WeekSubWeek", "ti", "tf")]
outlet = merge(out2, clust, by = "WeekSubWeek", all = T)
outlet = merge(outlet , qmDay, by.x = "WeekSubWeek", by.y = "SubWeeks", all = T)
outlet$DayMoYr = as.POSIXct(strptime(outlet$DayMoYr, "%Y-%m-%d", tz="EST"))
time = time[, c("tDayMoYr", "Jdays", "DayMoYr")]
outlet = merge(time, outlet, by = "DayMoYr", all = F)
outlet$ts = max(as.POSIXct(outlet$DayMoYr,  tz="EST"), as.POSIXct(outlet$ti,  tz="EST"))
max(as.POSIXct(outlet$ti[1],  tz="EST"), as.POSIXct(outlet$tf[1],  tz="EST"))
max(as.POSIXct(outlet$DayMoYr[1],  tz="EST"), as.POSIXct(outlet$tf[1],  tz="EST"))
outlet$ts = max(as.POSIXct(outlet$DayMoYr[1],  tz="EST"), as.POSIXct(outlet$tf[1],  tz="EST"))
outlet$ts = max(as.POSIXct(outlet$DayMoYr,  tz="EST"), as.POSIXct(outlet$tf,  tz="EST"))
outlet$ts = max(as.POSIXct(outlet$DayMoYr,  tz="EST"), as.POSIXct(outlet$tf,  tz="EST"), rm.na=F)
outlet = outlet[complete.cases(outlet$ti), ]
outlet$ts = max(as.POSIXct(outlet$DayMoYr,  tz="EST"), as.POSIXct(outlet$tf,  tz="EST"))
Sys.setlocale("LC_ALL", "English")
# Plotting functions
library("scales")
library("tidyr")
library("dplyr")
library("reshape")
library("zoo") # na.approx()
path = file.path("/Users/DayTightChunks/Documents/PhD/hydrological-monitoring")
time = read.csv2("/Users/DayTightChunks/Documents/PhD/Models/phd-model-master/Analysis/Data/Time.csv")
time$DayMoYr = as.POSIXct(strptime(time$Date, "%d/%m/%Y", tz="EST"))
#time$tDayMoYr = format(as.POSIXct(time$DayMoYr), "%Y-%m-%d %H:%M:%S")
source(file.path(path, "global.R"))
out = read.csv(file.path(path, "Data/MarkerResponse_R05.csv"))
names(out)
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv")
qmDay = qmDay[, c("DayMoYr", "SubWeeks", "Volday.L", "SmpHrs",
"ConcSmOut_ugL.obs", "ConcSmOut_ugL.sd" ,
"SmOut_ug.obs", "SmOut_ug.sd",
"delta.obs", "delta.sd" )]
names(qmDay)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";", dec = ",")
clust = clust[, c("Events", "WeekSubWeek", "Q.Ave", "T.Hrs", "Vol", "Q.Max", "Cluster",  "EventLabel")]
names(clust)
# Adding markers: ti and tf
out2 = out[, c("WeekSubWeek", "ti", "tf")]
outlet = merge(out2, clust, by = "WeekSubWeek", all = T)
outlet = merge(outlet , qmDay, by.x = "WeekSubWeek", by.y = "SubWeeks", all = T)
outlet$DayMoYr = as.POSIXct(strptime(outlet$DayMoYr, "%Y-%m-%d", tz="EST"))
time = time[, c("Jdays", "DayMoYr")]
outlet = merge(time, outlet, by = "DayMoYr", all = F)
#outlet$ts = ifelse(outlet$tDayMoYr > outlet$ti, outlet$tDayMoYr, outlet$ti)
#outlet$ts = max(as.POSIXct(outlet$DayMoYr,  tz="EST"), as.POSIXct(outlet$ti,  tz="EST"))
#outlet$tDayMoYr = as.POSIXct(outlet$tDayMoYr, tz="EST")
outlet = outlet[complete.cases(outlet$ti), ]
outlet$ts = max(as.POSIXct(outlet$DayMoYr,  tz="EST"), as.POSIXct(outlet$ti,  tz="EST"))
outlet$ts = ifelse(as.POSIXct(outlet$DayMoYr,  tz="EST") > as.POSIXct(outlet$ti,  tz="EST"), as.POSIXct(outlet$DayMoYr,  tz="EST"), as.POSIXct(outlet$ti,  tz="EST"))
outlet$ts = ifelse(outlet$DayMoYr > outlet$ti, outlet$DayMoYr, outlet$ti)
outlet$ti = as.POSIXct(strptime(outlet$ti, "%Y-%m-%d %H:%M:%S", tz="EST"))
View(outlet)
outlet$ts = ifelse(outlet$DayMoYr > outlet$ti, outlet$DayMoYr, outlet$ti)
outlet$ts = ifelse(outlet$DayMoYr > outlet$ti, as.POSIXct(outlet$DayMoYr,  tz="EST"), as.POSIXct(outlet$ti, tz="EST"))
View(outlet)
outlet$ts = ifelse(outlet$DayMoYr > outlet$ti,
as.POSIXct(strptime(outlet$DayMoYr, "%Y-%m-%d %H:%M:%S", tz="EST")),
as.POSIXct(strptime(outlet$ti, "%Y-%m-%d %H:%M:%S", tz="EST")))
View(outlet)
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv")
qmDay = qmDay[, c("DayMoYr", "SubWeeks", "Volday.L", "SmpHrs",
"ConcSmOut_ugL.obs", "ConcSmOut_ugL.sd" ,
"SmOut_ug.obs", "SmOut_ug.sd",
"delta.obs", "delta.sd" )]
names(qmDay)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";", dec = ",")
clust = clust[, c("Events", "WeekSubWeek", "Q.Ave", "T.Hrs", "Vol", "Q.Max", "Cluster",  "EventLabel")]
names(clust)
# Adding markers: ti and tf
out2 = out[, c("WeekSubWeek", "ti", "tf")]
outlet = merge(out2, clust, by = "WeekSubWeek", all = T)
outlet = merge(outlet , qmDay, by.x = "WeekSubWeek", by.y = "SubWeeks", all = T)
outlet$DayMoYr = as.POSIXct(strptime(outlet$DayMoYr, "%Y-%m-%d", tz="EST"))
outlet$ti = as.POSIXct(strptime(outlet$ti, "%Y-%m-%d %H:%M:%S", tz="EST"))
time = time[, c("Jdays", "DayMoYr")]
outlet = merge(time, outlet, by = "DayMoYr", all = F)
outlet = outlet[complete.cases(outlet$ti), ]
write.csv(outlet,
'BEACH_R/visuals_b2l_R04.csv', row.names = F)
# For plotting Discharge gainst chemo-bars
q = read.csv2(file.path(path, "Data/groupAlteck2016_R.csv"))
View(outlet)
q$Vol.L = q$Vol2min * 1000
q = q[ , c("Date", "Q.HW1", "DayMoYr", "Vol.L", "SubWeeks" )]
q$Q.Ls = q$Q.HW1*1000/60
qmDay = read.csv("BEACH_R/allOut_multiDay_R00.csv")
qmDay = qmDay[, c("DayMoYr", "SubWeeks", "Volday.L", "SmpHrs",
"ConcSmOut_ugL.obs", "ConcSmOut_ugL.sd" ,
"SmOut_ug.obs", "SmOut_ug.sd",
"delta.obs", "delta.sd" )]
names(qmDay)
clust = read.csv(file.path(path, "Data/PCA4Lutz_R_Oct2018.csv"), sep = ";", dec = ",")
clust = clust[, c("Events", "WeekSubWeek", "Q.Ave", "T.Hrs", "Vol", "Q.Max", "Cluster",  "EventLabel")]
names(clust)
# Adding markers: ti and tf
out2 = out[, c("WeekSubWeek", "ti", "tf")]
outlet = merge(out2, clust, by = "WeekSubWeek", all = T)
outlet = merge(outlet , qmDay, by.x = "WeekSubWeek", by.y = "SubWeeks", all = T)
outlet$DayMoYr = as.POSIXct(strptime(outlet$DayMoYr, "%Y-%m-%d", tz="EST"))
outlet$ti = as.POSIXct(strptime(outlet$ti, "%Y-%m-%d %H:%M:%S", tz="EST"))
time = time[, c("Jdays", "DayMoYr")]
outlet = merge(time, outlet, by = "DayMoYr", all = F)
outlet = outlet[complete.cases(outlet$ti), ]
write.csv(outlet,
'BEACH_R/visuals_b2l_R04.csv', row.names = F)
# For plotting Discharge gainst chemo-bars
q = read.csv2(file.path(path, "Data/groupAlteck2016_R.csv"))
q$Vol.L = q$Vol2min * 1000
q = q[ , c("Date", "Q.HW1", "DayMoYr", "Vol.L", "SubWeeks" )]
q$Q.Ls = q$Q.HW1*1000/60
library("dplyr")
library("ggplot2")
library("scales")
library("ggrepel")
library(tidyr)
setwd("/Users/DayTightChunks/Documents/PhD/shiny-hydro-app")
path_master = file.path("/Users/DayTightChunks/Documents/PhD/Models/phd-model-master/Analysis/Data")
constraints = read.csv(file.path(path_master, 'BEACH_R/visuals_b2l_R04.csv'))
View(constraints)
constraints = constraints[complete.cases(constraints$ConcSmOut_ugL.obs), ]
constraints = constraints[complete.cases(constraints$delta.obs), ]
constraints = read.csv(file.path(path_master, 'BEACH_R/visuals_b2l_R04.csv'))
